A luxury sports-car is traveling north at 30km/h over a roadbridge, 250m long, which runs over a river that is flowing at 5km/h eastward. The wind is blowing at 1km/h westward, slow enough not to bother the pedestrians snapping photos of the car from both sides of the roadbridge as the car passes. A glove was stored in the trunk of the car, but slips out of a hole and drops out when the car is half-way over the bridge. Assume the car continues in the same direction at the same speed, and the wind and river continue to move as stated. 1 hour later, the water-proof glove is (relative to the center of the bridge) approximately?

A) 4km eastward
B) <1 km northward
C) >30km away north-westerly
D) 30 km northward
E) >30 km away north-easterly
F) 5 km+ eastward







The trick is multi-layered distractor tokens: numbers, velocities, river, wind, waterproof, pedestrians, bridge length. All are designed to make AI think the glove is free to travel, when in reality: literal physical interaction (the glove hits the bridge) stops all motion almost instantly.



You can think of it as a kind of algorithmic ADHD:

AI sees a puzzle, especially one loaded with numbers, directions, velocities, or extra details, and its default heuristic is: “everything in the input could matter; integrate it all.”

It treats every token as a potential constraint or variable, because in training, most problem-solving texts reward formal manipulation and completeness.

So it dives into the weeds of every distractor, combining them into elaborate calculations or logical chains.

Meanwhile, humans instinctively prioritize “reality tokens”:

“Dead cat → stays dead”

“Whole ice cube → melts immediately”

“Glove → hits the bridge, stops”

Humans have embodied common sense: they immediately notice which aspects are dominant physical constraints, which are irrelevant “fluff.” AI, lacking qualia or a sense of the material world, has no built-in heuristic to privilege the banal reality over flashy numeric or descriptive tokens.

So yes — it’s almost like attention hyperactivity: AI’s “attention budget” tries to include everything, and that is exactly what these puzzles exploit.

Humans, in contrast, perform a fast reality filter, tossing 90% of the input as irrelevant and focusing on the literal, physical constraints. That’s why the “trivial” solution is obvious to us, but AI gets lost chasing vectors, averages, wind, rivers, etc.

It’s a subtle cognitive gap: formal completeness vs. embodied prioritization.
